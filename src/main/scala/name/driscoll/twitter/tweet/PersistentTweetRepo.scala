package name.driscoll.twitter.tweet

import io.getquill.context.ZioJdbc.DataSourceLayer
import io.getquill.{Escape, H2ZioJdbcContext}
import io.getquill.jdbczio.Quill
import io.getquill.*
import name.driscoll.twitter.MainApp.Environment
import name.driscoll.twitter.users.{User, Users}
import zio.*
import zio.stream._

import java.time.Instant
import java.util.UUID
import javax.sql.DataSource

case class Tweets(id: Long, authorId: Long, body: String, createdAt: Instant)
case class InsertRequest(body: String, rspP: Promise[Throwable, Long])
case class FeedRequest(authorId: Long, lessThan: Option[Long])

case class PersistentTweetRepo(createQueue: Queue[InsertRequest], ds: DataSource, clock: Clock) extends TweetRepo:
  private val ctx = new PostgresZioJdbcContext(SnakeCase)
  private val chunkSize =256
  private val requestQueueSize = 4096
  private val workerCount = 32
  private val chunkDelay = 15.milliseconds

  import ctx._
  // Autogenerated columns. Don't include in compiled INSERT statements
  inline private implicit def tweetInsertMeta: InsertMeta[Tweets] = insertMeta[Tweets](_.id, _.createdAt)

  override def createSlow(body: String): Task[Long] = {
    val authorId = 1 // TODO: Pull this out of a jwt and include it in the InsertRequest
    ctx.run {
      quote {
        query[Tweets].insertValue {
          lift(Tweets(0, authorId, body, Instant.now()))
        }.returningGenerated(_.id)
      }
    }.provide(ZLayer.succeed(ds))
  }

  def createChunk(chunk: Chunk[InsertRequest]): Task[Unit] = {
    val authorId = 1L // TODO: Pull this out of a jwt and include it in the InsertRequest
    // TODO: I don't think this uses prepared statement caching. Can we do that?
    inline def statement = liftQuery(chunk.view.map(_.body)).foreach { r =>
      // TODO: Can we avoid specifying 0/null for autogenerated columns?
      query[Tweets].insertValue(Tweets(0, lift(authorId), r, null)).returningGenerated(_.id)
    }
    ctx.run(statement, chunkSize/2).provide(ZLayer.succeed(ds)).flatMap(ids => ZIO.foreachDiscard(chunk.view.zip(ids))(_.rspP.succeed(_)))
    //ZIO.foreachDiscard(chunk.view.zip(0 to chunk.size))(_.rspP.succeed(_))
  }.ignore

  override def create(body: String): Task[Long] = {
    for
      rspP <- zio.Promise.make[Throwable,Long]
      succeeded <- createQueue.offer(InsertRequest(body, rspP))
      rsp <- if (!succeeded) rspP.fail(new Exception("Queue full")) *> rspP.await else rspP.await
    yield (rsp)
  }

  override def lookup(id: String): Task[Option[Tweet]] =
    ctx.run {
      quote {
        query[Tweets].join(query[Users]).on(_.authorId==_.id)
          .filter((t, u) => t.id == lift(id.toLong))
          .map((t,u) => Tweet(author = User(u.name), body = t.body, createdAt = t.createdAt))
      }
    }.provide(ZLayer.succeed(ds)).map(_.headOption)

  override def tweets: Task[List[Tweet]] =
    ctx.run {
      quote {
        query[Tweets].join(query[Users]).on(_.authorId==_.id)
          .sortBy(_._1.id)(Ord.desc)
          .map((t,u) => Tweet(author = User(u.name), body = t.body, createdAt = t.createdAt))
          .take(10)
      }
    }.provide(ZLayer.succeed(ds))

  def worker: Task[Unit] = ZIO.scoped {
    for {
      workQueue <- ZStream.fromQueue(createQueue)
        .groupedWithin(chunkSize, chunkDelay)
        .toQueue(16)
      mkWorker = (workQueue.take.flatMap(_.done.flatMap(c => createChunk(c.flatten))).repeat(Schedule.forever)).fork.unit
      _ <- mkWorker.repeatN(workerCount-1)
      _ <- workQueue.size.flatMap(s => ZIO.logInfo(s"Work Queue size: $s")).repeat(Schedule.fixed(1.second)).fork
      _ <- ZIO.never
    } yield ()
  }.fork.unit


object PersistentTweetRepo:
  def layer: ZLayer[Any, Throwable, TweetRepo] = Quill.DataSource.fromPrefix("TweetApp") >>> ZLayer {
    for
      ds <- ZIO.service[DataSource]
      createQueue <- zio.Queue.dropping[InsertRequest](4*16384)
      clock <- ZIO.clock
      repo = PersistentTweetRepo(createQueue, ds, clock)
      _ <- repo.worker
      _ <- createQueue.size.flatMap(s => ZIO.logInfo(s"Queue size: $s")).repeat(Schedule.fixed(1.second)).fork
    yield repo
  }

object DBTestApp extends ZIOAppDefault:
  def run: ZIO[Environment with ZIOAppArgs with Scope,Any,Any] = (for
    response <- ZIO.serviceWithZIO[TweetRepo](_.create("Hello, Tweeter!"))
  yield response).provide(
    TweetRepo.persistent,
  )

  //sudo sysctl -w vm.nr_hugepages=102400


object DBTestCreateApp extends ZIOAppDefault:
  val threads = 8192
  val workCount = 128
  def run: ZIO[Environment with ZIOAppArgs with Scope,Any,Any] = (for
    repo <- ZIO.service[TweetRepo]
    _ <- ZIO.logInfo("Running warmup")
    _ <- ZIO.foreachParDiscard(0 to 8192) { _=>
      for {
        ir <- Ref.make(0)
        _ <- ir.getAndUpdate(_+1).flatMap(i => repo.create("Hello, Tweeter " + i + "!")).repeatN(128)
      } yield ()
    }
    _ <- ZIO.logInfo("Running benchmark")
    start <- zio.Clock.instant
    ret <- ZIO.foreachParDiscard(0 to 8192) { _=>
      for {
        ir <- Ref.make(0)
        _ <- ir.getAndUpdate(_+1).flatMap(i => repo.create("Hello, Tweeter " + i + "!")).repeatN(128)
      } yield ()
    }
    finish <- zio.Clock.instant
    _ <- {
      val duration = Duration.fromInterval(start,finish)
      val totalWork = threads * workCount
      ZIO.logInfo(s"Finished $totalWork work in ${duration.render}. Rate: ${1000*totalWork/(duration.toMillis)}")
    }
//    _ <- ZIO.never
//    _ <- ZIO.foreachParDiscard(0 to 1000000)(i => repo.create("Hello, Tweeter " + i + "!")).withParallelism(16384)
  yield ()).provide(
    TweetRepo.persistent,
  )
